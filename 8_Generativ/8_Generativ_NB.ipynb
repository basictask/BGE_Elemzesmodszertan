{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generatív modellek: Naive Bayes (NB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adatok beolvasása\n",
    "A spam.csv e-mail szövegeket tartalmaz, hozzájuk tartozóan pedig a bináris osztályt, mely szerint spam (kéretlen) vagy ham (kért) üzenetről van-e szó.\n",
    "\n",
    "A modellezés célja olyan természetes nyelv felismerőt felállítani, amely képes eldönteni, kéretlen e-mail-t kaptunk-e."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam.csv', encoding='latin')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Átalakítás-vizualizáció"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([x for x in df.columns if 'Unnamed' in x], axis=1, inplace=True) # Unnamed oszlopok eldobása\n",
    "df.columns = ['class', 'text'] # Oszlopnevek átalakítása\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "df.groupby('class').count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Töltsük le az angol nyelvben taláható felesleges szavakat, mint az \"is\", \"at\"\n",
    "A stopszavak olyan szavak, amelyek nem hordoznak olyan jelentést, ami egyedi lenne az adott osztályra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Előfeldolgozás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer() # Ugyanazon szavak más alakú előfordulását lecsökkenti, pl. \"argue\", \"arguing\", \"argued\" \n",
    "words = stopwords.words(\"english\")\n",
    "\n",
    "df['processedtext'] = df['text'].apply(lambda x: \" \".join([stemmer.stem(i) for i in re.sub(\"[^a-zA-Z]\", \" \", x).split() if i not in words]).lower())\n",
    "\n",
    "print(df.shape)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test szétválasztás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['processedtext'], target, test_size=0.30, random_state=100)\n",
    "\n",
    "print(df.shape); print(X_train.shape); print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szavak vektorizálása: a szavak előfordulását gyakorisági vektorokká alakítja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF: Term-frequency: normalizált gyakoriság az egész dokumentumban\n",
    "# IDF: Inverse Document Frequency: Csökkenti azoknak a szavaknak a súlyát, amik dokumentum-szerte mindenhol előfordulnak\n",
    "vectorizer_tfidf = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "\n",
    "train_tfIdf = vectorizer_tfidf.fit_transform(X_train.values.astype('U'))\n",
    "\n",
    "test_tfIdf = vectorizer_tfidf.transform(X_test.values.astype('U'))\n",
    "\n",
    "print(vectorizer_tfidf.get_feature_names()[:10])\n",
    "\n",
    "print(\"Train dimenziók:\", train_tfIdf.shape)\n",
    "print(\"Test dimenziók:\", test_tfIdf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Osztályozó létrehozása, tanítása és predikció"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(train_tfIdf, y_train)\n",
    "\n",
    "pred2 = nb_classifier.predict(test_tfIdf) \n",
    "print(pred2[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrika "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_tfidf = metrics.accuracy_score(y_test, pred2)\n",
    "print(\"Accuracy:\",accuracy_tfidf)\n",
    "\n",
    "Conf_metrics_tfidf = metrics.confusion_matrix(y_test, pred2, labels=['ham', 'spam'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mtx(metrics_mtx):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    confusion_matrix_df = metrics_mtx\n",
    "\n",
    "    heatmap = sns.heatmap(confusion_matrix_df, annot=True, annot_kws={\"size\": 20}, fmt=\"d\") # Korrelációs mátrix \n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize = 14) \n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right',fontsize = 14)\n",
    "\n",
    "    plt.ylabel('True label', fontsize = 14)\n",
    "    plt.xlabel('Predicted label', fontsize = 14)\n",
    "    plt.show()\n",
    "\n",
    "plot_conf_mtx(Conf_metrics_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Próbáljuk ki ugyanezt az eljárást egy véletlen-erdővel (Random Forest)!\n",
    "A véletlen erdő egy együttes tanulási eljárás, amely training közben hoz létre döntési fákat. Előnye, hogy kevés konfigurációval mélyebb belátást biztosít az adatokban rejlő kapcsolatokra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 100)\n",
    "\n",
    "classifier.fit(train_tfIdf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF osztályozó kiértékelése\n",
    "Melyik teljesített jobban?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predRF = classifier.predict(test_tfIdf) \n",
    "print(predRF[:10])\n",
    "\n",
    "# Számoljuk ki a pontosságot\n",
    "accuracy_RF = metrics.accuracy_score(y_test, predRF)\n",
    "print(\"Accuracy:\", accuracy_RF)\n",
    "\n",
    "Conf_metrics_RF = metrics.confusion_matrix(y_test, predRF, labels=['ham', 'spam'])\n",
    "plot_conf_mtx(Conf_metrics_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 122.85,
   "position": {
    "height": "40px",
    "left": "1182px",
    "right": "20px",
    "top": "118px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
